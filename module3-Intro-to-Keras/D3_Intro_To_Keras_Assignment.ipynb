{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignmnet 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "                               import pandas as pd\n",
    "from sklearn.preprocessing     import StandardScaler\n",
    "from tensorflow                import keras\n",
    "from tensorflow.keras.models   import Sequential\n",
    "from tensorflow.keras.layers   import Dense\n",
    "\n",
    "from tensorflow.keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, ..., 2.10000e+01,\n",
       "        3.96900e+02, 1.87200e+01],\n",
       "       [2.17700e-02, 8.25000e+01, 2.03000e+00, ..., 1.47000e+01,\n",
       "        3.95380e+02, 3.11000e+00],\n",
       "       [4.89822e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "        3.75520e+02, 3.26000e+00],\n",
       "       ...,\n",
       "       [3.46600e-02, 3.50000e+01, 6.06000e+00, ..., 1.69000e+01,\n",
       "        3.62250e+02, 7.83000e+00],\n",
       "       [2.14918e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        2.61950e+02, 1.57900e+01],\n",
       "       [1.43900e-02, 6.00000e+01, 2.93000e+00, ..., 1.56000e+01,\n",
       "        3.76700e+02, 4.38000e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227, 13), (76, 13), (227,), (76,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_h     = df \n",
    "x_data   = df_h.drop(columns = ['target']) \n",
    "y_target = df_h['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data\n",
    "                                                   ,y_target\n",
    "                                                   ,train_size   = 0.75\n",
    "                                                   ,test_size    = 0.25\n",
    "                                                   ,random_state = 42\n",
    "                                                   )\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.34857634  0.68849544  1.00471507 -1.72394174 -0.48912153 -0.40509575\n",
      "   0.86637254 -0.31159032  1.45244244  0.16837256 -0.68948866 -0.72164815\n",
      "  -0.51178124]\n",
      " [-0.79124391  0.68849544  1.00471507 -0.07041452  0.18103973 -0.40509575\n",
      "   0.86637254  1.24578955 -0.68849544 -0.86461584  0.94086474 -0.72164815\n",
      "  -0.51178124]\n",
      " [ 1.09009327  0.68849544  1.98777679 -1.172766   -0.72692069 -0.40509575\n",
      "  -1.04301161 -0.26832977  1.45244244  0.68486676 -0.68948866 -0.72164815\n",
      "  -0.51178124]\n",
      " [ 0.86875949 -1.45244244  1.00471507 -0.07041452  0.39722078 -0.40509575\n",
      "   0.86637254 -2.3015757  -0.68849544  0.16837256 -0.68948866  0.2772185\n",
      "   1.1478522 ]\n",
      " [-0.45924323 -1.45244244  0.02165334 -0.62159026 -0.01352322 -0.40509575\n",
      "   0.86637254  0.51036017 -0.68849544  0.08229019  0.94086474 -0.72164815\n",
      "  -0.51178124]\n",
      " [-1.0125777   0.68849544 -0.96140838  0.59099636  1.39165361 -0.40509575\n",
      "  -1.04301161 -0.13854811  1.45244244 -0.86461584 -0.68948866  2.27495179\n",
      "   1.1478522 ]\n",
      " [ 0.42609191 -1.45244244  0.02165334  0.26029092  1.60783466  2.46855221\n",
      "  -1.04301161  0.07775465 -0.68849544 -0.86461584  0.94086474  1.27608514\n",
      "  -0.51178124]\n",
      " [ 0.42609191  0.68849544 -0.96140838 -1.72394174 -0.22970427 -0.40509575\n",
      "   0.86637254  0.25079686 -0.68849544 -0.77853347  0.94086474  0.2772185\n",
      "   1.1478522 ]\n",
      " [ 0.75809259  0.68849544  1.00471507  1.03193696 -0.03514132  2.46855221\n",
      "   0.86637254 -0.57115363  1.45244244 -0.00379217 -0.68948866 -0.72164815\n",
      "  -0.51178124]\n",
      " [-1.12324459  0.68849544  0.02165334 -0.62159026  0.39722078 -0.40509575\n",
      "   0.86637254  0.98622624 -0.68849544 -0.86461584  0.94086474 -0.72164815\n",
      "   1.1478522 ]]\n"
     ]
    }
   ],
   "source": [
    "#standarize(clean?)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler  = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "print(X_train[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
